{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provided split value: predict\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d339e70d8675>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[0mtext_to_bmes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 282\u001b[1;33m predict_word_lists, predict_tag_lists = build_corpus(\n\u001b[0m\u001b[0;32m    283\u001b[0m     \"predict\", make_vocab=False, data_dir=\"./ResumeNER\")\n\u001b[0;32m    284\u001b[0m train_word_lists, train_tag_lists, word2id, tag2id = build_corpus(\n",
      "\u001b[1;32m<ipython-input-1-d339e70d8675>\u001b[0m in \u001b[0;36mbuild_corpus\u001b[1;34m(split, make_vocab, data_dir)\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mline\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'\\r\\n'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m                 \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m                 \u001b[0mword_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m                 \u001b[0mtag_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 0)"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pickle\n",
    "from os.path import join\n",
    "from codecs import open\n",
    "from collections import Counter\n",
    "\n",
    "sys.path.append(\"..\")  # 将上级目录添加到Python路径\n",
    "\n",
    "\n",
    "def flatten_lists(lists):\n",
    "    flatten_list = []\n",
    "    for l in lists:\n",
    "        if type(l) == list:\n",
    "            flatten_list += l\n",
    "        else:\n",
    "            flatten_list.append(l)\n",
    "    return flatten_list\n",
    "\n",
    "\n",
    "def load_model(file_name):\n",
    "    \"\"\"用于加载模型\"\"\"\n",
    "    with open(file_name, \"rb\") as f:\n",
    "        model = pickle.load(f)\n",
    "    return model\n",
    "\n",
    "# LSTM模型训练的时候需要在word2id和tag2id加入PAD和UNK\n",
    "# 如果是加了CRF的lstm还要加入<start>和<end> (解码的时候需要用到)\n",
    "\n",
    "\n",
    "def extend_maps(word2id, tag2id, for_crf=True):\n",
    "    word2id['<unk>'] = len(word2id)\n",
    "    word2id['<pad>'] = len(word2id)\n",
    "    tag2id['<unk>'] = len(tag2id)\n",
    "    tag2id['<pad>'] = len(tag2id)\n",
    "    # 如果是加了CRF的bilstm  那么还要加入<start> 和 <end>token\n",
    "    if for_crf:\n",
    "        word2id['<start>'] = len(word2id)\n",
    "        word2id['<end>'] = len(word2id)\n",
    "        tag2id['<start>'] = len(tag2id)\n",
    "        tag2id['<end>'] = len(tag2id)\n",
    "\n",
    "    return word2id, tag2id\n",
    "\n",
    "\n",
    "def prepocess_data_for_lstmcrf(word_lists, tag_lists, test=False):\n",
    "    assert len(word_lists) == len(tag_lists)\n",
    "    for i in range(len(word_lists)):\n",
    "        word_lists[i].append(\"<end>\")\n",
    "        if not test:  # 如果是测试数据，就不需要加end token了\n",
    "            tag_lists[i].append(\"<end>\")\n",
    "\n",
    "    return word_lists, tag_lists\n",
    "\n",
    "\n",
    "def build_map(lists):\n",
    "    maps = {}\n",
    "    for list_ in lists:\n",
    "        for e in list_:\n",
    "            if e not in maps:\n",
    "                maps[e] = len(maps)\n",
    "\n",
    "    return maps\n",
    "\n",
    "\n",
    "def build_corpus(split, make_vocab=True, data_dir=\"./ResumeNER\"):\n",
    "    \"\"\"读取数据\"\"\"\n",
    "    print(f\"Provided split value: {split}\")  # 添加输出以查看传入的split值\n",
    "    assert split in ['train', 'dev', 'test', 'predict']\n",
    "\n",
    "    word_lists = []\n",
    "    tag_lists = []\n",
    "    with open(join(data_dir, split+\".char.bmes\"), 'r', encoding='utf-8') as f:\n",
    "        word_list = []\n",
    "        tag_list = []\n",
    "        for line in f:\n",
    "            if line != '\\r\\n':\n",
    "                word, tag = line.strip('\\n').split()\n",
    "                word_list.append(word)\n",
    "                tag_list.append(tag)\n",
    "            else:\n",
    "                word_lists.append(word_list)\n",
    "                tag_lists.append(tag_list)\n",
    "                word_list = []\n",
    "                tag_list = []\n",
    "\n",
    "    # 如果make_vocab为True，还需要返回word2id和tag2id\n",
    "    if make_vocab:\n",
    "        word2id = build_map(word_lists)\n",
    "        tag2id = build_map(tag_lists)\n",
    "        return word_lists, tag_lists, word2id, tag2id\n",
    "    else:\n",
    "        return word_lists, tag_lists\n",
    "\n",
    "\n",
    "def text_to_bmes(input_text, output_file):\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        for char in input_text:\n",
    "            if char == '\\n':\n",
    "                f.write('\\n')\n",
    "            else:\n",
    "                f.write(f'{char} O\\n')\n",
    "        f.write('\\n')\n",
    "\n",
    "\n",
    "class Metrics(object):\n",
    "    \"\"\"用于评价模型，计算每个标签的精确率，召回率，F1分数\"\"\"\n",
    "\n",
    "    def __init__(self, golden_tags, predict_tags, remove_O=False):\n",
    "\n",
    "        # [[t1, t2], [t3, t4]...] --> [t1, t2, t3, t4...]\n",
    "        self.golden_tags = flatten_lists(golden_tags)\n",
    "        self.predict_tags = flatten_lists(predict_tags)\n",
    "\n",
    "        if remove_O:  # 将O标记移除，只关心实体标记\n",
    "            self._remove_Otags()\n",
    "\n",
    "        # 辅助计算的变量\n",
    "        self.tagset = set(self.golden_tags)\n",
    "        self.correct_tags_number = self.count_correct_tags()\n",
    "        self.predict_tags_counter = Counter(self.predict_tags)\n",
    "        self.golden_tags_counter = Counter(self.golden_tags)\n",
    "\n",
    "        # 计算精确率\n",
    "        self.precision_scores = self.cal_precision()\n",
    "\n",
    "        # 计算召回率\n",
    "        self.recall_scores = self.cal_recall()\n",
    "\n",
    "        # 计算F1分数\n",
    "        self.f1_scores = self.cal_f1()\n",
    "\n",
    "    def cal_precision(self):\n",
    "\n",
    "        precision_scores = {}\n",
    "        for tag in self.tagset:\n",
    "            precision_scores[tag] = self.correct_tags_number.get(tag, 0) / \\\n",
    "                self.predict_tags_counter[tag]\n",
    "\n",
    "        return precision_scores\n",
    "\n",
    "    def cal_recall(self):\n",
    "\n",
    "        recall_scores = {}\n",
    "        for tag in self.tagset:\n",
    "            recall_scores[tag] = self.correct_tags_number.get(tag, 0) / \\\n",
    "                self.golden_tags_counter[tag]\n",
    "        return recall_scores\n",
    "\n",
    "    def cal_f1(self):\n",
    "        f1_scores = {}\n",
    "        for tag in self.tagset:\n",
    "            p, r = self.precision_scores[tag], self.recall_scores[tag]\n",
    "            f1_scores[tag] = 2*p*r / (p+r+1e-10)  # 加上一个特别小的数，防止分母为0\n",
    "        return f1_scores\n",
    "\n",
    "    def report_scores(self):\n",
    "        \"\"\"将结果用表格的形式打印出来，像这个样子：\n",
    "\n",
    "                      precision    recall  f1-score   support\n",
    "              B-LOC      0.775     0.757     0.766      1084\n",
    "              I-LOC      0.601     0.631     0.616       325\n",
    "             B-MISC      0.698     0.499     0.582       339\n",
    "             I-MISC      0.644     0.567     0.603       557\n",
    "              B-ORG      0.795     0.801     0.798      1400\n",
    "              I-ORG      0.831     0.773     0.801      1104\n",
    "              B-PER      0.812     0.876     0.843       735\n",
    "              I-PER      0.873     0.931     0.901       634\n",
    "\n",
    "          avg/total      0.779     0.764     0.770      6178\n",
    "        \"\"\"\n",
    "        # 打印表头\n",
    "        header_format = '{:>9s}  {:>9} {:>9} {:>9} {:>9}'\n",
    "        header = ['precision', 'recall', 'f1-score', 'support']\n",
    "        print(header_format.format('', *header))\n",
    "\n",
    "        row_format = '{:>9s}  {:>9.4f} {:>9.4f} {:>9.4f} {:>9}'\n",
    "        # 打印每个标签的 精确率、召回率、f1分数\n",
    "        for tag in self.tagset:\n",
    "            print(row_format.format(\n",
    "                tag,\n",
    "                self.precision_scores[tag],\n",
    "                self.recall_scores[tag],\n",
    "                self.f1_scores[tag],\n",
    "                self.golden_tags_counter[tag]\n",
    "            ))\n",
    "\n",
    "        # 计算并打印平均值\n",
    "        avg_metrics = self._cal_weighted_average()\n",
    "        print(row_format.format(\n",
    "            'avg/total',\n",
    "            avg_metrics['precision'],\n",
    "            avg_metrics['recall'],\n",
    "            avg_metrics['f1_score'],\n",
    "            len(self.golden_tags)\n",
    "        ))\n",
    "\n",
    "    def count_correct_tags(self):\n",
    "        \"\"\"计算每种标签预测正确的个数(对应精确率、召回率计算公式上的tp)，用于后面精确率以及召回率的计算\"\"\"\n",
    "        correct_dict = {}\n",
    "        for gold_tag, predict_tag in zip(self.golden_tags, self.predict_tags):\n",
    "            if gold_tag == predict_tag:\n",
    "                if gold_tag not in correct_dict:\n",
    "                    correct_dict[gold_tag] = 1\n",
    "                else:\n",
    "                    correct_dict[gold_tag] += 1\n",
    "\n",
    "        return correct_dict\n",
    "\n",
    "    def _cal_weighted_average(self):\n",
    "\n",
    "        weighted_average = {}\n",
    "        total = len(self.golden_tags)\n",
    "\n",
    "        # 计算weighted precisions:\n",
    "        weighted_average['precision'] = 0.\n",
    "        weighted_average['recall'] = 0.\n",
    "        weighted_average['f1_score'] = 0.\n",
    "        for tag in self.tagset:\n",
    "            size = self.golden_tags_counter[tag]\n",
    "            weighted_average['precision'] += self.precision_scores[tag] * size\n",
    "            weighted_average['recall'] += self.recall_scores[tag] * size\n",
    "            weighted_average['f1_score'] += self.f1_scores[tag] * size\n",
    "\n",
    "        for metric in weighted_average.keys():\n",
    "            weighted_average[metric] /= total\n",
    "\n",
    "        return weighted_average\n",
    "\n",
    "    def _remove_Otags(self):\n",
    "\n",
    "        length = len(self.golden_tags)\n",
    "        O_tag_indices = [i for i in range(length)\n",
    "                         if self.golden_tags[i] == 'O']\n",
    "\n",
    "        self.golden_tags = [tag for i, tag in enumerate(self.golden_tags)\n",
    "                            if i not in O_tag_indices]\n",
    "\n",
    "        self.predict_tags = [tag for i, tag in enumerate(self.predict_tags)\n",
    "                             if i not in O_tag_indices]\n",
    "        print(\"原总标记数为{}，移除了{}个O标记，占比{:.2f}%\".format(\n",
    "            length,\n",
    "            len(O_tag_indices),\n",
    "            len(O_tag_indices) / length * 100\n",
    "        ))\n",
    "\n",
    "    def report_confusion_matrix(self):\n",
    "        \"\"\"计算混淆矩阵\"\"\"\n",
    "\n",
    "        print(\"\\nConfusion Matrix:\")\n",
    "        tag_list = list(self.tagset)\n",
    "        # 初始化混淆矩阵 matrix[i][j]表示第i个tag被模型预测成第j个tag的次数\n",
    "        tags_size = len(tag_list)\n",
    "        matrix = []\n",
    "        for i in range(tags_size):\n",
    "            matrix.append([0] * tags_size)\n",
    "\n",
    "        # 遍历tags列表\n",
    "        for golden_tag, predict_tag in zip(self.golden_tags, self.predict_tags):\n",
    "            try:\n",
    "                row = tag_list.index(golden_tag)\n",
    "                col = tag_list.index(predict_tag)\n",
    "                matrix[row][col] += 1\n",
    "            except ValueError:  # 有极少数标记没有出现在golden_tags，但出现在predict_tags，跳过这些标记\n",
    "                continue\n",
    "\n",
    "        # 输出矩阵\n",
    "        row_format_ = '{:>7} ' * (tags_size+1)\n",
    "        print(row_format_.format(\"\", *tag_list))\n",
    "        for i, row in enumerate(matrix):\n",
    "            print(row_format_.format(tag_list[i], *row))\n",
    "\n",
    "\n",
    "inputStr2 = '周新钢是哪个案件的当事人？'\n",
    "\n",
    "\n",
    "input_text = inputStr2\n",
    "\n",
    "output_file = \"./ResumeNER/predict.char.bmes\"\n",
    "\n",
    "text_to_bmes(input_text, output_file)\n",
    "\n",
    "predict_word_lists, predict_tag_lists = build_corpus(\n",
    "    \"predict\", make_vocab=False, data_dir=\"./ResumeNER\")\n",
    "train_word_lists, train_tag_lists, word2id, tag2id = build_corpus(\n",
    "    \"train\", data_dir=\"./ResumeNER\")\n",
    "crf_word2id, crf_tag2id = extend_maps(word2id, tag2id, for_crf=True)\n",
    "bilstm_model = load_model('./ckpts/bilstm_crf.pkl')\n",
    "bilstm_model.model.bilstm.bilstm.flatten_parameters()  # remove warning\n",
    "predict_word_lists, predict_tag_lists = prepocess_data_for_lstmcrf(\n",
    "    predict_word_lists, predict_tag_lists, test=True\n",
    ")\n",
    "lstmcrf_pred, target_tag_list = bilstm_model.test(predict_word_lists, predict_tag_lists,\n",
    "                                                  crf_word2id, crf_tag2id)\n",
    "result_dict = {}\n",
    "current_name = []\n",
    "simplified_tags = [tag.split('-')[-1] for tag in lstmcrf_pred[0]]\n",
    "\n",
    "result_dict = {word: tag for word, tag in zip(input_text, simplified_tags)}\n",
    "\n",
    "print(result_dict)\n",
    "\n",
    "for word, tag in zip(input_text, simplified_tags):\n",
    "    if tag == \"NAME\":\n",
    "        current_name.append(word)\n",
    "    elif current_name:\n",
    "        name_str = ''.join(current_name)\n",
    "        if name_str not in result_dict:\n",
    "            result_dict[name_str] = \"NAME\"\n",
    "        current_name = []\n",
    "\n",
    "print(result_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
